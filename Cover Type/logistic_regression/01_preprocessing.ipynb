{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Data Preprocessing\n",
    "## Forest Cover Type Dataset\n",
    "\n",
    "This notebook prepares data for Logistic Regression modeling by:\n",
    "- Loading the raw dataset\n",
    "- Splitting into training and test sets\n",
    "- Applying standard scaling to all features\n",
    "- Saving processed data for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:47:56.038237Z",
     "iopub.status.busy": "2025-12-12T12:47:56.038237Z",
     "iopub.status.idle": "2025-12-12T12:47:57.262094Z",
     "shell.execute_reply": "2025-12-12T12:47:57.262094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:47:57.292006Z",
     "iopub.status.busy": "2025-12-12T12:47:57.292006Z",
     "iopub.status.idle": "2025-12-12T12:47:57.295530Z",
     "shell.execute_reply": "2025-12-12T12:47:57.295014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOGISTIC REGRESSION PREPROCESSING\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOGISTIC REGRESSION PREPROCESSING\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Locate Dataset\n",
    "\n",
    "The script searches for `covtype.csv` in multiple possible locations to ensure robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:47:57.297072Z",
     "iopub.status.busy": "2025-12-12T12:47:57.297072Z",
     "iopub.status.idle": "2025-12-12T12:47:57.301042Z",
     "shell.execute_reply": "2025-12-12T12:47:57.300527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found dataset at: C:\\PYTHON\\AIT511 Course Project 2\\archive\\covtype.csv\n"
     ]
    }
   ],
   "source": [
    "script_dir = os.path.abspath('../..')\n",
    "parent_dir = os.path.dirname(script_dir)\n",
    "\n",
    "possible_paths = [\n",
    "    os.path.join(script_dir, 'covtype.csv'),\n",
    "    os.path.join(parent_dir, 'covtype.csv'),\n",
    "    'covtype.csv',\n",
    "    '../covtype.csv',\n",
    "    '../../covtype.csv'\n",
    "]\n",
    "\n",
    "csv_path = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        csv_path = path\n",
    "        break\n",
    "\n",
    "if csv_path is None:\n",
    "    print(f\"Error: covtype.csv not found!\")\n",
    "    print(f\"Checked paths:\")\n",
    "    for path in possible_paths:\n",
    "        print(f\"  - {path}\")\n",
    "    raise FileNotFoundError(\"covtype.csv not found in any expected location\")\n",
    "\n",
    "print(f\"✓ Found dataset at: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:47:57.303053Z",
     "iopub.status.busy": "2025-12-12T12:47:57.303053Z",
     "iopub.status.idle": "2025-12-12T12:47:58.245652Z",
     "shell.execute_reply": "2025-12-12T12:47:58.245652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] Loading dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset loaded: (581012, 55)\n",
      "  - Rows: 581,012\n",
      "  - Columns: 55\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n[1/5] Loading dataset...\")\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"✓ Dataset loaded: {df.shape}\")\n",
    "print(f\"  - Rows: {df.shape[0]:,}\")\n",
    "print(f\"  - Columns: {df.shape[1]}\")\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Features and Target\n",
    "\n",
    "The last column contains the target variable (Cover_Type), and all other columns are features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:47:58.248274Z",
     "iopub.status.busy": "2025-12-12T12:47:58.248274Z",
     "iopub.status.idle": "2025-12-12T12:47:58.270082Z",
     "shell.execute_reply": "2025-12-12T12:47:58.269559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (581012, 54)\n",
      "Target shape: (581012,)\n",
      "\n",
      "Target classes: [1 2 3 4 5 6 7]\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget classes: {np.unique(y)}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split Data\n",
    "\n",
    "We use an 80-20 split with stratification to maintain class distribution in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:47:58.272610Z",
     "iopub.status.busy": "2025-12-12T12:47:58.271599Z",
     "iopub.status.idle": "2025-12-12T12:47:58.907710Z",
     "shell.execute_reply": "2025-12-12T12:47:58.907198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/5] Splitting data (80% train, 20% test)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data split complete\n",
      "  - Training samples: 464,809\n",
      "  - Test samples: 116,203\n",
      "  - Features: 54\n",
      "\n",
      "Class distribution in training set:\n",
      "  Class 1: 169,472 (36.46%)\n",
      "  Class 2: 226,640 (48.76%)\n",
      "  Class 3: 28,603 ( 6.15%)\n",
      "  Class 4:  2,198 ( 0.47%)\n",
      "  Class 5:  7,594 ( 1.63%)\n",
      "  Class 6: 13,894 ( 2.99%)\n",
      "  Class 7: 16,408 ( 3.53%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[2/5] Splitting data (80% train, 20% test)...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"✓ Data split complete\")\n",
    "print(f\"  - Training samples: {X_train.shape[0]:,}\")\n",
    "print(f\"  - Test samples: {X_test.shape[0]:,}\")\n",
    "print(f\"  - Features: {X_train.shape[1]}\")\n",
    "\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    percentage = (count / len(y_train)) * 100\n",
    "    print(f\"  Class {cls}: {count:6,} ({percentage:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Scaling\n",
    "\n",
    "Logistic Regression benefits from standardized features (mean=0, std=1).\n",
    "We fit the scaler on training data and apply it to both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:47:58.909716Z",
     "iopub.status.busy": "2025-12-12T12:47:58.908724Z",
     "iopub.status.idle": "2025-12-12T12:47:59.504153Z",
     "shell.execute_reply": "2025-12-12T12:47:59.503615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/5] Applying Standard Scaling...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data scaled (mean=0, variance=1)\n",
      "\n",
      "Scaling verification (training set):\n",
      "  - Mean: -0.000000 (should be ~0)\n",
      "  - Std: 1.000000 (should be ~1)\n",
      "  - Min: -11.296430\n",
      "  - Max: 393.618258\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3/5] Applying Standard Scaling...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"✓ Data scaled (mean=0, variance=1)\")\n",
    "\n",
    "print(\"\\nScaling verification (training set):\")\n",
    "print(f\"  - Mean: {X_train_scaled.mean():.6f} (should be ~0)\")\n",
    "print(f\"  - Std: {X_train_scaled.std():.6f} (should be ~1)\")\n",
    "print(f\"  - Min: {X_train_scaled.min():.6f}\")\n",
    "print(f\"  - Max: {X_train_scaled.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data\n",
    "\n",
    "Save the processed data and scaler for use in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:47:59.506183Z",
     "iopub.status.busy": "2025-12-12T12:47:59.505184Z",
     "iopub.status.idle": "2025-12-12T12:48:01.650676Z",
     "shell.execute_reply": "2025-12-12T12:48:01.650676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/5] Saving processed data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved processed data to: C:\\PYTHON\\AIT511 Course Project 2\\archive\\data_logistic\\logistic_data.npz\n",
      "✓ Saved scaler to: C:\\PYTHON\\AIT511 Course Project 2\\archive\\data_logistic\\scaler.joblib\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4/5] Saving processed data...\")\n",
    "\n",
    "output_dir = os.path.join(script_dir, 'data_logistic')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "data_file = os.path.join(output_dir, 'logistic_data.npz')\n",
    "np.savez_compressed(\n",
    "    data_file,\n",
    "    X_train=X_train_scaled,\n",
    "    X_test=X_test_scaled,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "scaler_file = os.path.join(output_dir, 'scaler.joblib')\n",
    "joblib.dump(scaler, scaler_file)\n",
    "\n",
    "print(f\"✓ Saved processed data to: {data_file}\")\n",
    "print(f\"✓ Saved scaler to: {scaler_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:48:01.652719Z",
     "iopub.status.busy": "2025-12-12T12:48:01.652719Z",
     "iopub.status.idle": "2025-12-12T12:48:01.661525Z",
     "shell.execute_reply": "2025-12-12T12:48:01.661525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PREPROCESSING COMPLETE\n",
      "================================================================================\n",
      "✓ Total samples: 581,012\n",
      "✓ Training samples: 464,809\n",
      "✓ Test samples: 116,203\n",
      "✓ Features: 54\n",
      "✓ Classes: 7\n",
      "\n",
      "Data ready for Logistic Regression training!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"✓ Total samples: {len(y):,}\")\n",
    "print(f\"✓ Training samples: {len(y_train):,}\")\n",
    "print(f\"✓ Test samples: {len(y_test):,}\")\n",
    "print(f\"✓ Features: {X_train.shape[1]}\")\n",
    "print(f\"✓ Classes: {len(np.unique(y))}\")\n",
    "print(f\"\\nData ready for Logistic Regression training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}