{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Advanced Data Preprocessing\n",
    "## Forest Cover Type Dataset\n",
    "\n",
    "This notebook implements advanced feature engineering to maximize neural network performance.\n",
    "\n",
    "### Feature Engineering Techniques:\n",
    "1. **Domain-specific interactions** (hydrology, elevation)\n",
    "2. **Coordinate rotations** (linear combinations)\n",
    "3. **Cyclical encoding** (Aspect angles)\n",
    "4. **Categorical embeddings** (Wilderness Areas, Soil Types)\n",
    "5. **Robust scaling** for features with extreme values\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:03.618866Z",
     "iopub.status.busy": "2025-12-12T12:50:03.617866Z",
     "iopub.status.idle": "2025-12-12T12:50:04.268895Z",
     "shell.execute_reply": "2025-12-12T12:50:04.268895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:04.296631Z",
     "iopub.status.busy": "2025-12-12T12:50:04.296631Z",
     "iopub.status.idle": "2025-12-12T12:50:04.300437Z",
     "shell.execute_reply": "2025-12-12T12:50:04.300437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NEURAL NETWORK PREPROCESSING (ADVANCED FEATURE ENGINEERING)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"NEURAL NETWORK PREPROCESSING (ADVANCED FEATURE ENGINEERING)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Locate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:04.301445Z",
     "iopub.status.busy": "2025-12-12T12:50:04.301445Z",
     "iopub.status.idle": "2025-12-12T12:50:04.306039Z",
     "shell.execute_reply": "2025-12-12T12:50:04.306039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found dataset at: C:\\PYTHON\\AIT511 Course Project 2\\archive\\covtype.csv\n"
     ]
    }
   ],
   "source": [
    "script_dir = os.path.abspath('../..')\n",
    "\n",
    "possible_paths = [\n",
    "    os.path.join(script_dir, 'covtype.csv'),\n",
    "    os.path.join(script_dir, '../covtype.csv'),\n",
    "    os.path.join(script_dir, '../../covtype.csv'),\n",
    "    'covtype.csv',\n",
    "    '../covtype.csv'\n",
    "]\n",
    "\n",
    "csv_path = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        csv_path = path\n",
    "        break\n",
    "\n",
    "if csv_path is None:\n",
    "    print(\"Error: covtype.csv not found!\")\n",
    "    raise FileNotFoundError(\"covtype.csv not found\")\n",
    "\n",
    "print(f\"✓ Found dataset at: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:04.308046Z",
     "iopub.status.busy": "2025-12-12T12:50:04.308046Z",
     "iopub.status.idle": "2025-12-12T12:50:05.083404Z",
     "shell.execute_reply": "2025-12-12T12:50:05.083404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset loaded: (581012, 55)\n",
      "  - Rows: 581,012\n",
      "  - Columns: 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nLoading dataset...\")\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"✓ Dataset loaded: {df.shape}\")\n",
    "print(f\"  - Rows: {df.shape[0]:,}\")\n",
    "print(f\"  - Columns: {df.shape[1]}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Core Feature Interactions\n",
    "\n",
    "Create domain-specific features based on hydrological and geological knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:05.085719Z",
     "iopub.status.busy": "2025-12-12T12:50:05.085719Z",
     "iopub.status.idle": "2025-12-12T12:50:05.118980Z",
     "shell.execute_reply": "2025-12-12T12:50:05.118980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/3] Generating Domain-Specific Interactions...\n",
      "  ✓ Created: Hydro_Elevation\n",
      "  ✓ Created: Hydro_Euclidean\n",
      "  ✓ Created: Hydro_Manhattan\n",
      "  ✓ Created: Distance sum features\n",
      "  ✓ Created: Absolute difference features\n",
      "  ✓ Created: Mean_Dist_Amenities\n",
      "\n",
      "Total engineered features so far: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1/3] Generating Domain-Specific Interactions...\")\n",
    "\n",
    "df['Hydro_Elevation'] = df['Elevation'] - df['Vertical_Distance_To_Hydrology']\n",
    "print(\"  ✓ Created: Hydro_Elevation\")\n",
    "\n",
    "df['Hydro_Euclidean'] = np.sqrt(\n",
    "    df['Horizontal_Distance_To_Hydrology']**2 + \n",
    "    df['Vertical_Distance_To_Hydrology']**2\n",
    ")\n",
    "print(\"  ✓ Created: Hydro_Euclidean\")\n",
    "\n",
    "df['Hydro_Manhattan'] = (\n",
    "    abs(df['Horizontal_Distance_To_Hydrology']) + \n",
    "    abs(df['Vertical_Distance_To_Hydrology'])\n",
    ")\n",
    "print(\"  ✓ Created: Hydro_Manhattan\")\n",
    "\n",
    "df['Dist_Hydro_Fire'] = (\n",
    "    df['Horizontal_Distance_To_Hydrology'] + \n",
    "    df['Horizontal_Distance_To_Fire_Points']\n",
    ")\n",
    "df['Dist_Hydro_Road'] = (\n",
    "    df['Horizontal_Distance_To_Hydrology'] + \n",
    "    df['Horizontal_Distance_To_Roadways']\n",
    ")\n",
    "df['Dist_Fire_Road'] = (\n",
    "    df['Horizontal_Distance_To_Fire_Points'] + \n",
    "    df['Horizontal_Distance_To_Roadways']\n",
    ")\n",
    "print(\"  ✓ Created: Distance sum features\")\n",
    "\n",
    "df['Abs_Dist_Hydro_Fire'] = abs(\n",
    "    df['Horizontal_Distance_To_Hydrology'] - \n",
    "    df['Horizontal_Distance_To_Fire_Points']\n",
    ")\n",
    "df['Abs_Dist_Hydro_Road'] = abs(\n",
    "    df['Horizontal_Distance_To_Hydrology'] - \n",
    "    df['Horizontal_Distance_To_Roadways']\n",
    ")\n",
    "print(\"  ✓ Created: Absolute difference features\")\n",
    "\n",
    "df['Mean_Dist_Amenities'] = (\n",
    "    df['Horizontal_Distance_To_Hydrology'] + \n",
    "    df['Horizontal_Distance_To_Roadways'] + \n",
    "    df['Horizontal_Distance_To_Fire_Points']\n",
    ") / 3\n",
    "print(\"  ✓ Created: Mean_Dist_Amenities\")\n",
    "\n",
    "print(f\"\\nTotal engineered features so far: 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Linear Rotations\n",
    "\n",
    "Create linear combinations of key features to help neural networks capture diagonal decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:05.121497Z",
     "iopub.status.busy": "2025-12-12T12:50:05.120491Z",
     "iopub.status.idle": "2025-12-12T12:50:05.149230Z",
     "shell.execute_reply": "2025-12-12T12:50:05.149230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/3] Applying Linear Rotations...\n",
      "  ✓ Created 12 rotation features from 4 base features\n",
      "  ✓ Total pairwise combinations: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[2/3] Applying Linear Rotations...\")\n",
    "\n",
    "cols_to_rotate = [\n",
    "    'Horizontal_Distance_To_Hydrology',\n",
    "    'Horizontal_Distance_To_Roadways',\n",
    "    'Horizontal_Distance_To_Fire_Points',\n",
    "    'Elevation'\n",
    "]\n",
    "\n",
    "rotation_count = 0\n",
    "for col1, col2 in itertools.combinations(cols_to_rotate, 2):\n",
    "    df[f'{col1}_plus_{col2}'] = df[col1] + df[col2]\n",
    "    df[f'{col1}_minus_{col2}'] = df[col1] - df[col2]\n",
    "    rotation_count += 2\n",
    "\n",
    "print(f\"  ✓ Created {rotation_count} rotation features from {len(cols_to_rotate)} base features\")\n",
    "print(f\"  ✓ Total pairwise combinations: {len(list(itertools.combinations(cols_to_rotate, 2)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cyclical Aspect Encoding\n",
    "\n",
    "Aspect is a circular variable (0° = 360°), so we use sine/cosine encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:05.151263Z",
     "iopub.status.busy": "2025-12-12T12:50:05.151263Z",
     "iopub.status.idle": "2025-12-12T12:50:05.168822Z",
     "shell.execute_reply": "2025-12-12T12:50:05.168822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding cyclical Aspect feature...\n",
      "  ✓ Created: Aspect_Sin, Aspect_Cos\n",
      "  Note: This preserves the circular nature of compass directions\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEncoding cyclical Aspect feature...\")\n",
    "\n",
    "df['Aspect_Sin'] = np.sin(np.radians(df['Aspect']))\n",
    "df['Aspect_Cos'] = np.cos(np.radians(df['Aspect']))\n",
    "\n",
    "print(\"  ✓ Created: Aspect_Sin, Aspect_Cos\")\n",
    "print(\"  Note: This preserves the circular nature of compass directions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:05.171371Z",
     "iopub.status.busy": "2025-12-12T12:50:05.171371Z",
     "iopub.status.idle": "2025-12-12T12:50:05.174268Z",
     "shell.execute_reply": "2025-12-12T12:50:05.174268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Summary:\n",
      "============================================================\n",
      "Original features: 54\n",
      "Current total features: 78\n",
      "Engineered features: 24\n",
      "\n",
      "New feature categories:\n",
      "  - Hydrological interactions: 10\n",
      "  - Linear rotations: 12\n",
      "  - Cyclical encoding: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFeature Engineering Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Original features: 54\")\n",
    "print(f\"Current total features: {len(df.columns)}\")\n",
    "print(f\"Engineered features: {len(df.columns) - 54}\")\n",
    "print(\"\\nNew feature categories:\")\n",
    "print(\"  - Hydrological interactions: 10\")\n",
    "print(f\"  - Linear rotations: {rotation_count}\")\n",
    "print(\"  - Cyclical encoding: 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prepare Arrays\n",
    "\n",
    "Separate continuous features, categorical features, and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:05.176302Z",
     "iopub.status.busy": "2025-12-12T12:50:05.176302Z",
     "iopub.status.idle": "2025-12-12T12:50:05.281477Z",
     "shell.execute_reply": "2025-12-12T12:50:05.281477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/3] Preparing arrays...\n",
      "  - Wilderness Area columns: 4\n",
      "  - Soil Type columns: 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Created categorical indices for embeddings\n",
      "  ✓ Total continuous features: 32\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3/3] Preparing arrays...\")\n",
    "\n",
    "wild_cols = [c for c in df.columns if 'Wilderness_Area' in c]\n",
    "soil_cols = [c for c in df.columns if 'Soil_Type' in c]\n",
    "\n",
    "print(f\"  - Wilderness Area columns: {len(wild_cols)}\")\n",
    "print(f\"  - Soil Type columns: {len(soil_cols)}\")\n",
    "\n",
    "df['Wilderness_Area_Index'] = np.argmax(df[wild_cols].values, axis=1)\n",
    "df['Soil_Type_Index'] = np.argmax(df[soil_cols].values, axis=1)\n",
    "\n",
    "print(\"  ✓ Created categorical indices for embeddings\")\n",
    "\n",
    "exclude_cols = ['Cover_Type', 'Aspect'] + wild_cols + soil_cols\n",
    "cont_features = [c for c in df.columns if c not in exclude_cols and 'Index' not in c]\n",
    "\n",
    "print(f\"  ✓ Total continuous features: {len(cont_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Extract Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:05.283487Z",
     "iopub.status.busy": "2025-12-12T12:50:05.283487Z",
     "iopub.status.idle": "2025-12-12T12:50:05.375218Z",
     "shell.execute_reply": "2025-12-12T12:50:05.375218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Array shapes:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - Continuous features: (581012, 32)\n",
      "  - Wilderness indices: (581012,)\n",
      "  - Soil indices: (581012,)\n",
      "  - Target: (581012,)\n"
     ]
    }
   ],
   "source": [
    "X_cont = df[cont_features].values.astype(np.float32)\n",
    "X_wild = df['Wilderness_Area_Index'].values\n",
    "X_soil = df['Soil_Type_Index'].values\n",
    "y = df['Cover_Type'].values\n",
    "\n",
    "print(f\"\\nArray shapes:\")\n",
    "print(f\"  - Continuous features: {X_cont.shape}\")\n",
    "print(f\"  - Wilderness indices: {X_wild.shape}\")\n",
    "print(f\"  - Soil indices: {X_soil.shape}\")\n",
    "print(f\"  - Target: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:05.376731Z",
     "iopub.status.busy": "2025-12-12T12:50:05.376731Z",
     "iopub.status.idle": "2025-12-12T12:50:05.643750Z",
     "shell.execute_reply": "2025-12-12T12:50:05.643750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data (85% train, 15% test)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data split complete\n",
      "  - Training samples: 493,860\n",
      "  - Test samples: 87,152\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSplitting data (85% train, 15% test)...\")\n",
    "\n",
    "train_idx, test_idx, y_train, y_test = train_test_split(\n",
    "    np.arange(len(df)), \n",
    "    y, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_cont_train = X_cont[train_idx]\n",
    "X_cont_test = X_cont[test_idx]\n",
    "X_wild_train = X_wild[train_idx]\n",
    "X_wild_test = X_wild[test_idx]\n",
    "X_soil_train = X_soil[train_idx]\n",
    "X_soil_test = X_soil[test_idx]\n",
    "\n",
    "print(f\"✓ Data split complete\")\n",
    "print(f\"  - Training samples: {len(train_idx):,}\")\n",
    "print(f\"  - Test samples: {len(test_idx):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Robust Scaling\n",
    "\n",
    "Use RobustScaler instead of StandardScaler to handle outliers better, especially in hydrology features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:05.645263Z",
     "iopub.status.busy": "2025-12-12T12:50:05.645263Z",
     "iopub.status.idle": "2025-12-12T12:50:06.406122Z",
     "shell.execute_reply": "2025-12-12T12:50:06.406122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Robust Scaling...\n",
      "  Note: RobustScaler handles outliers better than StandardScaler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scaling complete\n",
      "\n",
      "Scaling verification (training set):\n",
      "  - Median: 0.000000 (should be ~0)\n",
      "  - IQR: ~1 for most features\n",
      "  - Min: -9.416667\n",
      "  - Max: 9.209678\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nApplying Robust Scaling...\")\n",
    "print(\"  Note: RobustScaler handles outliers better than StandardScaler\")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_cont_train = scaler.fit_transform(X_cont_train)\n",
    "X_cont_test = scaler.transform(X_cont_test)\n",
    "\n",
    "print(\"✓ Scaling complete\")\n",
    "\n",
    "print(\"\\nScaling verification (training set):\")\n",
    "print(f\"  - Median: {np.median(X_cont_train):.6f} (should be ~0)\")\n",
    "print(f\"  - IQR: ~1 for most features\")\n",
    "print(f\"  - Min: {X_cont_train.min():.6f}\")\n",
    "print(f\"  - Max: {X_cont_train.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Encode Target Variable\n",
    "\n",
    "Convert to one-hot encoding for neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:06.408130Z",
     "iopub.status.busy": "2025-12-12T12:50:06.408130Z",
     "iopub.status.idle": "2025-12-12T12:50:06.422787Z",
     "shell.execute_reply": "2025-12-12T12:50:06.422787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding target variable...\n",
      "✓ Target encoded\n",
      "  - Training shape: (493860, 7)\n",
      "  - Test shape: (87152, 7)\n",
      "  - Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEncoding target variable...\")\n",
    "\n",
    "y_train_cat = pd.get_dummies(y_train - 1).values\n",
    "y_test_cat = pd.get_dummies(y_test - 1).values\n",
    "\n",
    "print(f\"✓ Target encoded\")\n",
    "print(f\"  - Training shape: {y_train_cat.shape}\")\n",
    "print(f\"  - Test shape: {y_test_cat.shape}\")\n",
    "print(f\"  - Number of classes: {y_train_cat.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:06.424795Z",
     "iopub.status.busy": "2025-12-12T12:50:06.424795Z",
     "iopub.status.idle": "2025-12-12T12:50:09.428776Z",
     "shell.execute_reply": "2025-12-12T12:50:09.428776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving processed data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved to: C:\\PYTHON\\AIT511 Course Project 2\\archive\\data_95_v2\\advanced_data_v2.npz\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving processed data...\")\n",
    "\n",
    "output_dir = os.path.join(script_dir, 'data_95_v2')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_file = os.path.join(output_dir, 'advanced_data_v2.npz')\n",
    "np.savez_compressed(\n",
    "    output_file,\n",
    "    X_cont_train=X_cont_train,\n",
    "    X_cont_test=X_cont_test,\n",
    "    X_wild_train=X_wild_train,\n",
    "    X_wild_test=X_wild_test,\n",
    "    X_soil_train=X_soil_train,\n",
    "    X_soil_test=X_soil_test,\n",
    "    y_train_cat=y_train_cat,\n",
    "    y_test_cat=y_test_cat\n",
    ")\n",
    "\n",
    "print(f\"✓ Saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T12:50:09.430291Z",
     "iopub.status.busy": "2025-12-12T12:50:09.430291Z",
     "iopub.status.idle": "2025-12-12T12:50:09.434525Z",
     "shell.execute_reply": "2025-12-12T12:50:09.434525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "NEURAL NETWORK PREPROCESSING COMPLETE\n",
      "================================================================================\n",
      "✓ Original features: 54\n",
      "✓ Continuous features: 32\n",
      "✓ Categorical features: 2 (Wilderness, Soil)\n",
      "✓ Training samples: 493,860\n",
      "✓ Test samples: 87,152\n",
      "✓ Classes: 7\n",
      "\n",
      "Feature Engineering Applied:\n",
      "  - Domain-specific interactions\n",
      "  - Linear rotations (45° combinations)\n",
      "  - Cyclical encoding (Aspect)\n",
      "  - Categorical embeddings (Wilderness, Soil)\n",
      "  - Robust scaling (outlier-resistant)\n",
      "\n",
      "Data ready for Neural Network training !\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEURAL NETWORK PREPROCESSING COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"✓ Original features: 54\")\n",
    "print(f\"✓ Continuous features: {X_cont_train.shape[1]}\")\n",
    "print(f\"✓ Categorical features: 2 (Wilderness, Soil)\")\n",
    "print(f\"✓ Training samples: {len(y_train):,}\")\n",
    "print(f\"✓ Test samples: {len(y_test):,}\")\n",
    "print(f\"✓ Classes: {y_train_cat.shape[1]}\")\n",
    "print(f\"\\nFeature Engineering Applied:\")\n",
    "print(f\"  - Domain-specific interactions\")\n",
    "print(f\"  - Linear rotations (45° combinations)\")\n",
    "print(f\"  - Cyclical encoding (Aspect)\")\n",
    "print(f\"  - Categorical embeddings (Wilderness, Soil)\")\n",
    "print(f\"  - Robust scaling (outlier-resistant)\")\n",
    "print(f\"\\nData ready for Neural Network training !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}